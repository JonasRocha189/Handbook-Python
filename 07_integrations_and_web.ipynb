{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "b67941ae", "cell_type": "markdown", "source": "# Section 7 \u2014 Integrations & Web\nThis section introduces how Python interacts with the web, including APIs, scraping, and basic automation.\n\nThe focus here is **conceptual understanding** with short code snippets.", "metadata": {}}, {"id": "1d51e25f", "cell_type": "markdown", "source": "## 7.1 HTTP Requests & APIs\nModern data projects often involve pulling data from external APIs.\n\n**Key points:**\n- Use the `requests` library to send HTTP GET or POST requests.\n- Parse responses, often returned in JSON format.\n- Handle errors and rate limits.\n\n### Example: Fetching JSON data from an API", "metadata": {}}, {"id": "c2773c78", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "import requests\n\n# Example GET request to a public API (placeholder URL)\nurl = 'https://api.example.com/data'\nresponse = requests.get(url)\n\nif response.status_code == 200:\n    data = response.json()\n    print('Sample data:', list(data.items())[:5])\nelse:\n    print('Error:', response.status_code)", "outputs": []}, {"id": "e173076c", "cell_type": "markdown", "source": "## 7.2 Web Scraping\nSometimes data isn\u2019t available through APIs and must be scraped from web pages.\n\n### Static Pages\n- Use **BeautifulSoup** to parse HTML and extract elements like titles, tables, and links.\n- Be mindful of website terms of service.\n\n### Example: Conceptual Snippet", "metadata": {}}, {"id": "f48be506", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "from bs4 import BeautifulSoup\n\nhtml_doc = '<html><body><h1>Hello Web</h1></body></html>'\nsoup = BeautifulSoup(html_doc, 'html.parser')\nprint(soup.h1.text)", "outputs": []}, {"id": "209cbd84", "cell_type": "markdown", "source": "### Dynamic Pages\n- Some sites load data via JavaScript; static scraping won\u2019t capture it.\n- Use tools like **Selenium** to automate a web browser.\n- Selenium can find elements by CSS selectors or XPath and retrieve dynamic content.\n\n_In this guide we keep it conceptual, no live browser example included._", "metadata": {}}, {"id": "55250d8f", "cell_type": "markdown", "source": "## 7.3 Building Web APIs and Apps\nTo serve models or build interactive applications, Python can expose APIs.\n\n### Flask\n- A lightweight web framework for creating REST APIs and web apps.\n- Define routes and return JSON responses.\n\n### FastAPI\n- A modern alternative to Flask.\n- Automatically generates OpenAPI documentation and is production\u2011friendly.\n\n### Example Flask Snippet:", "metadata": {}}, {"id": "837b7bc3", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/hello', methods=['GET'])\ndef hello():\n    return jsonify({'message': 'Hello from Flask!'})\n\n# Run with: flask run (after saving to a file)\n# Visit http://127.0.0.1:5000/hello", "outputs": []}, {"id": "70d24187", "cell_type": "markdown", "source": "## 7.4 Automation & Scheduling\nReal\u2011world analytics often requires running tasks automatically:\n\n- **n8n**: A no\u2011code/low\u2011code automation platform to integrate APIs and workflows.\n- **cron**: Unix tool for scheduling scripts.\n- **Apache Airflow**: For managing complex data pipelines.\n\n### Conceptual Example\n- Use Python scripts to fetch data daily.\n- Schedule via cron or orchestrate with Airflow.\n- Integrate into n8n to connect APIs, web scraping, and storage systems.", "metadata": {}}, {"id": "76b8af70", "cell_type": "markdown", "source": "> \u26a0\ufe0f **Best Practices:**\n- Always follow website robots.txt and API usage policies.\n- Implement error handling and logging.\n- Secure sensitive API keys using environment variables.", "metadata": {}}]}